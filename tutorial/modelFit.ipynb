{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beginning-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recreational-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and prepare handwrite dataset MNIST\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#Convert the samples from integers to floating-point numbers\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "civilian-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking layers with tf.keras.sequential\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tribal-middle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1287159 , -0.11702058, -0.33869356,  0.40986308,  0.5213046 ,\n",
       "        -0.00935646, -0.29219097,  0.2307339 , -0.00068968,  0.46565157]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For each example the model returns a vector of \"logits\" or \"log-odds\" scores, one fro each class.\n",
    "#\"logits\": The vector of raw(non-normalized) predictions that a classification model generates, which is ordinarily then passed to a normalization function\n",
    "predictions=model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "valuable-material",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0987326 , 0.07722156, 0.06186816, 0.130786  , 0.14620414,\n",
       "        0.08599961, 0.06481314, 0.10933681, 0.0867482 , 0.1382897 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stone-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "annual-midnight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4534123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "narrative-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recorded-consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 498us/step - loss: 0.2932 - accuracy: 0.9150\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 509us/step - loss: 0.1420 - accuracy: 0.9584\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.1070 - accuracy: 0.9676\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 488us/step - loss: 0.0870 - accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 513us/step - loss: 0.0752 - accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2982e6c5ee0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.fit method adjusts the model parameters to minimize the loss\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exempt-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0806 - accuracy: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08057327568531036, 0.9761000275611877]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Model.evaluate method checks the models performance, usually on a \"Validation-set\" or \"Test-set\"\n",
    "# \"Validation-set\": A subset of the dataset-disjoint from the training set-used in validation\n",
    "# \"Test-set\": The subset of the dataset that you use to test your model after the model has gone through initial vetting by the calidation set\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incredible-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1.5441293e-08, 8.9756091e-10, 4.5218112e-06, 4.0119619e-05,\n",
       "        1.6275093e-13, 2.2289888e-09, 1.8628609e-14, 9.9995494e-01,\n",
       "        9.0706365e-08, 2.6374826e-07],\n",
       "       [1.1455138e-08, 2.4697743e-04, 9.9974519e-01, 7.6100378e-06,\n",
       "        6.9937912e-16, 1.2342971e-07, 9.4739427e-08, 1.2251430e-14,\n",
       "        4.2900375e-08, 1.3664695e-14],\n",
       "       [3.5536823e-07, 9.9663121e-01, 4.3199939e-04, 2.1041300e-05,\n",
       "        2.0667838e-04, 9.1609072e-06, 9.3059698e-06, 2.3760002e-03,\n",
       "        3.1265980e-04, 1.5769783e-06],\n",
       "       [9.9996102e-01, 9.9216935e-13, 2.2505226e-05, 2.0271939e-08,\n",
       "        9.2748968e-07, 2.2315461e-07, 5.0015615e-07, 1.1646466e-05,\n",
       "        2.6513207e-09, 3.0938625e-06],\n",
       "       [7.8768528e-07, 6.5897034e-09, 3.8173271e-06, 2.3221176e-07,\n",
       "        9.9572110e-01, 1.4259351e-07, 2.0551304e-06, 4.0414576e-05,\n",
       "        2.6172839e-07, 4.2311302e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack one more layer \"softmax\" to return a probability \n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "probability_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
